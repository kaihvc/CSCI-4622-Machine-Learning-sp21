{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "02804d34b749993749a391fe95bd7520",
     "grade": false,
     "grade_id": "cell-39cc69ad672c2457",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 4: SVM\n",
    "\n",
    "\n",
    "This assignment is due on Moodle by **11:59pm on Monday March 31**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://github.com/akkikiki/CSCI-4622-Machine-Learning-sp21/blob/main/info/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda (Version: 2019.07) with Python 3.7. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "- In this homework you will explore the primal and dual representations of support vector machines, as well as the performance of various kernels while classifying sentiments. Install the following packages: `nltk` (Version: 3.5), `scikit-learn` (Version: 0.23.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b6a65990e3ee338fcca6169ba1c4d1ff",
     "grade": false,
     "grade_id": "cell-42609c0d44322df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Please put your name and cuidentity username.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Kai Hueske-VanCeylon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identity Key**: kahu1945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for deterministic output\n",
    "np.random.seed(5622)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bcadea9323aaa669deed90d8c5ea2f4b",
     "grade": false,
     "grade_id": "cell-1e40b611c0a33948",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[40 Points] Problem 1 - Basic concepts of SVM\n",
    "---\n",
    "\n",
    "### Part 1 [10 points]\n",
    "* What are the main differences between the primal and the dual representations?\n",
    "* For the variables $\\xi_i$, $C$ in the primal formation, what are their roles? Write out the upper/lower bounds (constraints) of these variables. What are the interpretation for these maximum/minimum values?\n",
    "* For the variable $\\alpha_i$, $\\beta_i$ in the dual formation, what are the upper/lower bound (constraints) of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f616bf5ea6cd25ba5b9bbbf94bb465f5",
     "grade": true,
     "grade_id": "cell-f177349aed9aabcf",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The primal representation only supports linear classification, and doesn't allow the use of kernels. The dual SVM representation includes a Lagrangian objective function, and allows kernels to be used to extend the SVM's applicability to non-linear classification problems.  \n",
    "The variables in $\\xi$ are the slack variables. They allow the SVM to have a \"soft margin\", allowing points to be classified as a particular cluster despite being on the wrong side of the decision boundary. $C$ determines how heavily these slack variables are weighted the objective function, which affects how the SVM is fitted. $C$ has a lower bound of 0, at which point the slack variables aren't taken into consideration at all, and the SVM becomes hard-margin.  \n",
    "The slack variables $\\xi$ also have a lower bound of 0. This is because data points on the correct side of the margin don't need slack variables to correct them. Data within the margin have slack variables between 0 and 1, since they're within 1 margin of the correct side, and data on the wrong side of the margin have slack variables greater than 1.\n",
    "\n",
    "In the dual representation, $0 \\leq \\alpha_i \\leq C$, and for the corresponding $\\beta_i$, $\\alpha_i + \\beta_i = C$ (which naturally means $0 \\leq \\beta_i \\leq C$ as well)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9711d8637903ea332d20ecae46de997",
     "grade": false,
     "grade_id": "cell-fe7878b1dd2ff1df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [20 points]\n",
    "\n",
    " * Given a weight vector, implement the `find_support` function that returns the indices of the support vectors.\n",
    " * Given a weight vector, implement the `find_slack` function that returns the indices of the vectors with nonzero slack.\n",
    " * Given the alpha dual vector, implement the `weight_vector` function that returns the corresponding weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "03db7fcb00d613cbf64708dc2a27b9ab",
     "grade": false,
     "grade_id": "cell-14c104d96c00c2eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.kINSP = np.array([\n",
    "            (1, 8, +1),\n",
    "            (7, 2, -1),\n",
    "            (6, -1, -1),\n",
    "            (-5, 0, +1),\n",
    "            (-5, 1, -1),\n",
    "            (-5, 2, +1),\n",
    "            (6, 3, +1),\n",
    "            (6, 1, -1),\n",
    "            (5, 2, -1)\n",
    "        ])\n",
    "        self.kSEP = np.array([\n",
    "            (-2, 2, +1),    # 0 - A\n",
    "            (0, 4, +1),     # 1 - B\n",
    "            (2, 1, +1),     # 2 - C\n",
    "            (-2, -3, -1),   # 3 - D\n",
    "            (0, -1, -1),    # 4 - E\n",
    "            (2, -3, -1),    # 5 - F\n",
    "        ])\n",
    "\n",
    "\n",
    "    def weight_vector(self, x, y, alpha):\n",
    "        \"\"\"\n",
    "        Given a vector of alphas, compute the primal weight vector w.\n",
    "        The vector w should be returned as an Numpy array.\n",
    "        \n",
    "        Returns:\n",
    "            w (np.ndarray): The primal weight vector w.\n",
    "        \"\"\"\n",
    "        w = np.zeros(len(x[0]))\n",
    "        for i in range(len(x)):\n",
    "            w += (alpha[i] * y[i] * x[i])\n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "    def find_support(self, x, y, w, b, tolerance=0.001):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all of the support vectors as a set.\n",
    "        \n",
    "        Returns:\n",
    "            support (set) : set of support vector indices\n",
    "        \"\"\"\n",
    "        support = set()\n",
    "        for i in range(len(x)):\n",
    "            if y[i] * (np.dot(w, x[i]) + b) <= 1 + tolerance:\n",
    "                support.add(i)\n",
    "        return support\n",
    "\n",
    "\n",
    "\n",
    "    def find_slack(self, x, y, w, b):\n",
    "        \"\"\"\n",
    "        Given a set of training examples and primal weights, return the indices\n",
    "        of all examples with nonzero slack as a set.\n",
    "        \n",
    "        Returns:\n",
    "            slack (set) : set of slack indices \n",
    "        \"\"\"\n",
    "\n",
    "        slack = set()\n",
    "        for i in range(len(x)):\n",
    "            if y[i] * (np.dot(w, x[i]) + b) < 1:\n",
    "                slack.add(i)\n",
    "        return slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aa73cc220bc2b16c09b0e72ebd10dfa",
     "grade": true,
     "grade_id": "cell-3c7d7f432578009e",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TestWideSlack (tests.tests.TestSVM) ... ok\n",
      "TestNarrowSlack (tests.tests.TestSVM) ... ok\n",
      "TestSupport (tests.tests.TestSVM) ... ok\n",
      "TestWeight (tests.tests.TestSVM) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.022s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite(\"prob 1\", SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b842153bbb481e2a662612aaa95c8979",
     "grade": false,
     "grade_id": "cell-7c25ab5ed0d77621",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [10 points]\n",
    "\n",
    "The goal of this problem is to correctly classify test data points, given a training data set.\n",
    "For this problem, assume that we are training an SVM with a quadratic kernel, which means our kernel function is a polynomial kernel of degree 2. You are given the data set presented in the figure below. The slack penalty $C$ will determine the location of the decision boundary.\n",
    "\n",
    "Justify the following questions in a sentence or via drawing decision boundary.\n",
    "![training_data](./data/data.png)\n",
    "\n",
    "* Where would the decision boundary be for very large values of $C$ ?\n",
    "* Where you would expect the decision boundary to be if  $C = 0$ ?\n",
    "* Which of the two cases above would you expect to generalize better on test data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "985db05b9496fb3714ee2096479f6f7d",
     "grade": true,
     "grade_id": "cell-02406ba497be1623",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$C$ indicates how much weight we give to the slack variables in the objective function. For a high $C$ value, less deviation from the decision boundary will be accepted, so it will be close to the green points, curving around them.  This version is more complex, and would probably tend to overfit.  \n",
    "For a low $C$ value like 0, more deviation will be allowed, so the decision boundary will just try to maximize the margin, which would mean the decision boundary would be almost diagonally, sloping down to the right, and in the middle of the space between the two clusters of points. The two red points which are grouped with the green cluster would be on the wrong side of the boundary, but the slack variables would let them be classified correctly. This version is less complex, and would tend to generalize better to test data, because it doesn't constrain the categories as strongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bef866dff5b0ce6c9dea5e7aea37f23a",
     "grade": false,
     "grade_id": "cell-55888810e6151283",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[30 points] Problem 2 - The Kernel Trick\n",
    "---\n",
    "The kernel trick can make SVM powerful and become non-linear. In this problem we will get familiar with the kernel trick.\n",
    "\n",
    "### Part 1 [10 points]\n",
    "\n",
    "We will construct a support vector machine that computes the XOR function, using values of +1 and −1 (instead of 1 and 0) for both inputs and outputs, so that an example looks like ($[−1, 1], 1$) or ($[−1, −1], −1$). \n",
    "- Map the input $[x_1, x_2]$ into a space consisting of $x_1$ and $x_1x_2$. \n",
    "- Plot the four input points in this space, and the maximal margin separator. \n",
    "- Give the margin value in the markdown cell. \n",
    "\n",
    "Remember to indicate which points have output +1 and which -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0fe2b7a9339f72690a8459981899a23",
     "grade": true,
     "grade_id": "cell-20ea52b04bb94dee",
     "locked": false,
     "points": 8,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_vals = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])\n",
    "\n",
    "# map input, define outputs\n",
    "mapped = np.array([[x[0], x[0] * x[1]] for x in input_vals])\n",
    "output_vals = np.array([0, 1, 1, 0])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(mapped[:, 0], mapped[:, 1])\n",
    "for i, x in enumerate(input_vals):\n",
    "    ax.annotate(output_vals[i], mapped[i], textcoords='offset pixels', xytext=(10, 0))\n",
    "    \n",
    "# boundary\n",
    "ax.plot([-1, 1], [0, 0], color='red', label='decision boundary')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e73071136adefa9aed2ebcd5957bd69a",
     "grade": true,
     "grade_id": "cell-64bbc4980b5c4edd",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Our weights vector is $\\textbf{w} = [0, 1]^T$. This means our margin is $M = \\frac{2}{||\\textbf{w}||} = \\frac{2}{\\sqrt{0^2 + 1^2}} = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "387213f9cb504ea0e2fc596e89d0f919",
     "grade": false,
     "grade_id": "cell-5ba884cd7e49d78d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [5 points]\n",
    "Plot the separating line of **Part 1** back in the original Euclidean input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6e323e18881c3d6be9b1ff2abd3d8ac",
     "grade": true,
     "grade_id": "cell-9020bbe03ed87cfc",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kaih2\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\text.py:1163: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.linspace(-2, -1 * (1 / 25), 25)\n",
    "y1 = 1 / x1\n",
    "x2 = np.linspace(1 * (1 / 25), 2, 25)\n",
    "y2 = 1 / x2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(input_vals[:, 0], input_vals[:, 1])\n",
    "for i in range(len(input_vals)):\n",
    "    ax.annotate(input_vals[i], input_vals[i], textcoords='offset pixels', xytext=(10, 0))\n",
    "    \n",
    "# boundary\n",
    "ax.plot(x1, y1, color='red', label='decision boundary')\n",
    "ax.plot(x2, y2, color='red')\n",
    "ax.set_ylim([-2, 2])\n",
    "ax.set_xlim([-2, 2])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d978690256991b3b10176a46bb25febe",
     "grade": false,
     "grade_id": "cell-3013de14effe2d4a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [5 points]\n",
    "Is the separator in **Part 1** linear? Is the one in **Part 2** linear? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8821f5382c580de24c483bd1a0cd4b31",
     "grade": true,
     "grade_id": "cell-119e16472d287f4e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The separator in part 1 is linear; it's just a line in its space. The one in part 2, however, is not linear; in the original euclidean space, it has the equation $x_2 = \\frac{1}{x_1}$, which is not linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95b20466fd3ca86119c013f75bc4656f",
     "grade": false,
     "grade_id": "cell-b8218f37ba88f7c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4 [10 points]\n",
    "The key point of the so-called “kernel trick” in SVMs is to learn a classifier that effectively separates the training data in a higher dimensional space without having to explicitly compute the representation $\\phi(\\mathbf{x})$ of every point $\\mathbf{x}$ in the original input space. Instead, all the work is done through the kernel function $K(\\mathbf{x}_i, \\mathbf{x}_i)$, for example, we can use $K(\\mathbf{x}_i, \\mathbf{x}_i) = \\phi(\\mathbf{x}_i)\\phi(\\mathbf{x}_j)$.\n",
    "\n",
    "Show how to compute the squared Euclidean distance in the projected space between any two points $\\mathbf{x}_i$, $\\mathbf{x}_j$ in the original space without explicitly computing the $\\phi$ mapping, instead using the kernel function $K$. In other words, derive $d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = (\\phi(\\mathbf{x}_i) - \\phi(\\mathbf{x}_j))\\cdot(\\phi(\\mathbf{x}_i) - \\phi(\\mathbf{x}_j))$ into a form using only the kernel function.\n",
    "\n",
    "Please remember to simplify your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3beedd96d39e9c464377ae2885f78ba0",
     "grade": true,
     "grade_id": "cell-c6b6512e7d992202",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "$d(\\phi(\\mathbf{x}_i), \\phi(\\mathbf{x}_j)) = (\\phi(\\mathbf{x}_i) - \\phi(\\mathbf{x}_j))\\cdot(\\phi(\\mathbf{x}_i) - \\phi(\\mathbf{x}_j)) \\\\\n",
    "= \\phi(\\mathbf{x}_i)\\phi(\\mathbf{x}_i) - 2\\phi(\\mathbf{x}_i)\\phi(\\mathbf{x}_j) + \\phi(\\mathbf{x}_j))\\phi(\\mathbf{x}_j)) \\\\\n",
    "= K(\\mathbf{x}_i, \\mathbf{x}_i) - 2K(\\mathbf{x}_i, \\mathbf{x}_j) + K(\\mathbf{x}_j, \\mathbf{x}_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eda0db6d3653c96ec72059179ddb52ec",
     "grade": false,
     "grade_id": "cell-2a7361023bfbbe84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[30 points] Problem 3 - SVM with `sklearn`\n",
    "---\n",
    "\n",
    "In this problem, you will get familiar with important practical functions in scikit-learn such as pipeline, grid search, and cross validation. You will experiment with these using support vector machines.\n",
    "\n",
    "Note that grid search can take some time on your laptop, so make sure that your code is correct with a small subset of the training data and search a reasonable number of options.\n",
    "\n",
    "* Use the Sklearn implementation of support vector machines to train a classifier to distinguish Positive and negative sentiments\n",
    "* Experiment with linear, polynomial, and RBF kernels. First, perform a GridSearch over each kernel function and a small set of parameters defined over a wide range to help narrow down the search space.\n",
    "* Then choose the best performing kernel from your coarse scale search and define a narrower set of parameters for random search to further optimize the hyperparameters. Comment on the experiments you ran and optimal hyperparameters you found.\n",
    "Hint: http://scikit-learn.org/stable/modules/grid_search.html\n",
    "* Evaluate classification performance for each model for optimal parameters by testing on a hold-out set.\n",
    "\n",
    "Following is a dataset containing reviews and sentiments associated with it.\n",
    "\n",
    "We will create a SVM Classifier to predict positive or negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sizes] train: 4000, test: 1000\n",
      "[Avg S] train: 0.49875, test: 0.505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "reviews  = pd.read_csv('./data/reviews.csv')\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=5622)\n",
    "X_train = train['reviews']\n",
    "X_test = test['reviews']\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']\n",
    "\n",
    "# Print some data info\n",
    "print(f'[Sizes] train: {len(X_train)}, test: {len(X_test)}')\n",
    "print(f'[Avg S] train: {sum(y_train)/len(X_train)}, test: {sum(y_test)/len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kaih2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "# download nltk data\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = set(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3824735b35e2893522e59b8f68ebf486",
     "grade": false,
     "grade_id": "cell-c5af7b0df4f72c74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 1 [5 points]\n",
    "\n",
    "Complete the `get_vectorizer` and `get_kfolds` functions below.\n",
    "\n",
    "- Use [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to vectorize reviews as dictionary of term frequencies.\n",
    "- Define the crossvalidation split using [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html?highlight=stratifiedkfold#sklearn.model_selection.StratifiedKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "196749f1263ab6c54cc354afa9b5c4c3",
     "grade": false,
     "grade_id": "cell-ab58d371c35713b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def tokenize(text): \n",
    "    \"\"\"\n",
    "    Separate text into tokens\n",
    "    \"\"\"\n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def get_vectorizer():\n",
    "    \"\"\" \n",
    "    \n",
    "    Create and return a CountVectorizer\n",
    "    \n",
    "    Hints:\n",
    "        Read docs on CountVectorizer to set arguments (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) \n",
    "        Pass the above tokenize function as the tokenizer.\n",
    "        Use en_stopwords variable above as stopwords\n",
    "        \n",
    "        Play with different parameters.\n",
    "        min_df argument can help with generalizability\n",
    "    \"\"\"\n",
    "    \n",
    "    vectorizer = CountVectorizer(tokenizer=tokenize, max_df=0.8, min_df=0.3)\n",
    "    return vectorizer\n",
    "\n",
    "def get_kfolds():\n",
    "    \"\"\" \n",
    "    Split dataset into 5 splits using StratifiedKFold \n",
    "    \n",
    "    Hint:\n",
    "    Remember to shuffle\n",
    "    \"\"\"\n",
    "    kfolds = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    return kfolds\n",
    "\n",
    "\n",
    "vectorizer = get_vectorizer()\n",
    "kfolds = get_kfolds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3fabfb15f1d4ee78f5d2f9aa72193a59",
     "grade": true,
     "grade_id": "cell-7b9737faea74ccef",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for grading; please ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75b3eb30df1712dcef3a3334c4f4c8b8",
     "grade": false,
     "grade_id": "cell-ddb76d3c6bae8e15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [10 points]\n",
    "* Create a pipeline with our `CountVectorizer` object in **Part 1** and an SVM Classifier.\n",
    "* Create and fit a `GridSearchCV` object with the following parameter values:\n",
    "  * Linear kernel, $C = 0.01, 1.0, 10.0$\n",
    "  * Polynomial kernel, $\\text{degree} = 2, 3$, $\\gamma = 0.1, 0.5, 1$\n",
    "  * RBF kernel, $\\gamma = 0.1, 0.5, 1$\n",
    "* Report accuracy on the best estimator from our `GridSearchCV` object. (Choose `GridSearchCV`'s `n_jobs` parameter as 1 if your system doesn't support multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f8d29528eda0679df9787ebc7a3d812e",
     "grade": false,
     "grade_id": "cell-a3dd5b25a9ce8feb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    }
   ],
   "source": [
    "def get_pipeline(**kwargs):\n",
    "    \"\"\"\n",
    "        Define pipeline using make_pipeline (see sklearn docs) with vectorizer and SVM Classifier. \n",
    "        \n",
    "        The SVM Classifer should take in all kwargs passed (passing kwargs can be achieved with fn(**kwargs))\n",
    "        You should use balanced class weights for SVM.\n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline_svm = make_pipeline(vectorizer, SVC(**kwargs, class_weight='balanced'))\n",
    "    return pipeline_svm\n",
    "\n",
    "def get_course_params():\n",
    "    \"\"\"\n",
    "        Create the grid search parameters defined above for course grid search. \n",
    "        Returns a list of dictionaries to be passed as argument to GridSearchCV below\n",
    "    \"\"\"\n",
    "    \n",
    "    param_grid = {\n",
    "        'svc__C': [0.01, 1.0, 10.0],\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__degree': [3],\n",
    "        'svc__gamma': [0.1, 0.5, 1]\n",
    "    }\n",
    "    return param_grid\n",
    "\n",
    "def get_grid_svm():\n",
    "    \"\"\"\n",
    "        Create GridSearchCV with pipeline and the grid search parameters given above using \"accuracy\" for scoring.\n",
    "    \"\"\" \n",
    "     \n",
    "    param_grid = get_course_params()\n",
    "    pipeline_svm = get_pipeline()\n",
    "    \n",
    "    grid_svm = GridSearchCV(\n",
    "        pipeline_svm, \n",
    "        param_grid, \n",
    "        scoring='accuracy', \n",
    "        cv=kfolds,\n",
    "        n_jobs=-1,\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    return grid_svm\n",
    "    \n",
    "# pipeline = get_pipeline()\n",
    "# print(pipeline.get_params().keys())\n",
    "\n",
    "grid_svm = get_grid_svm()\n",
    "# debug_size = int(len(X_train) / 80)\n",
    "# X_debug = X_train[:debug_size]\n",
    "# y_debug = y_train[:debug_size]\n",
    "# _ = grid_svm.fit(X_debug, y_debug)\n",
    "# For debugging purposes, it makes sense to use a smaller set of training set to speed up the grid search progress\n",
    "# refit is not necessary since by default refit is true in GridSearchCV, \n",
    "# but we did this to show that you need to use the best parameter to fit the whole training set\n",
    "_ = grid_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "68a1aabe495c06e761fe8f6ce92d667f",
     "grade": true,
     "grade_id": "cell-fb57090849f1d094",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8819e90ae6a2708015ffaa2865cfd394",
     "grade": false,
     "grade_id": "cell-47833f7ec14a9d22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'svc__C': 0.01, 'svc__degree': 3, 'svc__gamma': 0.1, 'svc__kernel': 'poly'} | best cv score: 0.7942499999999999\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_svm.best_params_\n",
    "best_score = grid_svm.best_score_\n",
    "\n",
    "# Store best parameters and CV score from grid search for reporting into the variables above\n",
    "\n",
    "# Report best parameters and CV score from grid search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bf1df17e0bfe9499ed65aeda57e96c8c",
     "grade": true,
     "grade_id": "cell-1268040b2d1a98b4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ef3c4187f1be7404dd2fb775bb68dea1",
     "grade": false,
     "grade_id": "cell-a561071b8ec246bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [10 points]\n",
    "\n",
    "Choose the best performing kernel and parameter values from your coarse scale grid search and use them to set up a narrower range of parameter values. We will use randomized grid search to sample a fixed number of these candidate parameter sets for cross validation. The number of sampled parameter sets `n_iter` provides a trade-off between computational cost and quality of the \"optimal\" parameters. Feel free to experiment with different values of this parameter, but please change it back to `n_iter = 5` before submitting your assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8a05d6ba748a96b7b451774b54a41134",
     "grade": true,
     "grade_id": "cell-e1116a343a3e645a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "def get_params_fine_scale():\n",
    "    \"\"\"\n",
    "        Set param_grid to a dictionary containing parameter values for fine scale search.\n",
    "        Return value is passed as argument to RandomizedSearchCV below\n",
    "    \"\"\" \n",
    "    search_params = ['svc__C', 'svc__gamma']\n",
    "    param_grid = dict()\n",
    "    for param in best_params:\n",
    "        if param in search_params:\n",
    "            center = best_params[param]\n",
    "            param_grid[param] = list(np.linspace(center / 2, 1.5 * center, 10))\n",
    "        else:\n",
    "            param_grid[param] = [best_params[param]]\n",
    "    return param_grid\n",
    "\n",
    "\n",
    "def get_random_svm():\n",
    "    \"\"\"\n",
    "        Create randomized parameter search over fine scale grid;\n",
    "        Do NOT change the value of n_iter in the submitted version of your notebook.\n",
    "    \"\"\" \n",
    "    n_iter = 5\n",
    "    pipeline_svm = get_pipeline()\n",
    "    param_grid = get_params_fine_scale()\n",
    "\n",
    "    random_svm = RandomizedSearchCV(\n",
    "        pipeline_svm,\n",
    "        param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv = kfolds,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=1,   \n",
    "        n_jobs=-1 # you can change the n_jobs parameter to -1 if your system supports multi-prcoessing\n",
    "    )\n",
    "    return random_svm\n",
    "\n",
    "random_svm = get_random_svm()\n",
    "# debug_size = int(len(X_train) / 80)\n",
    "# X_debug = X_train[:debug_size]\n",
    "# y_debug = y_train[:debug_size]\n",
    "# refit is not necessary since by default refit is true in RandomSearchCV, \n",
    "# but we did this to show that you need to use the best parameter to fit the whole training set\n",
    "_ = random_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "125f0f9cacebf47639d09fd315e2c960",
     "grade": false,
     "grade_id": "cell-39b5a8b9e508cf0e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'svc__kernel': 'poly', 'svc__gamma': 0.061111111111111116, 'svc__degree': 3, 'svc__C': 0.011666666666666665} | best cv score: 0.7975\n"
     ]
    }
   ],
   "source": [
    "best_params = random_svm.best_params_\n",
    "best_score = random_svm.best_score_\n",
    "\n",
    "# Store best parameters and score from random search for reporting into the variables above \n",
    "\n",
    "# Report best parameters and score from random search\n",
    "print(f'best params: {best_params} | best cv score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78ef3b52d32ae25d6d538048785d9e88",
     "grade": true,
     "grade_id": "cell-5fd96d17e21f469c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For grading; please ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    # Reports various model metrics.  \n",
    "    pred = model.predict(X)        \n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8183556405353729,\n",
       " 'acc': 0.81,\n",
       " 'precision': 0.7911275415896488,\n",
       " 'recall': 0.8475247524752475}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test metrics.\n",
    "report_results(random_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c7739604efa929d396b9cf11c0d8114a",
     "grade": false,
     "grade_id": "cell-a47ce46465ea41d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4 [5 points]\n",
    "\n",
    "Explain the overall procedure, and report the final result including which hyperparameter values were chosen. Make sure to explain your reasoning in choosing a refined parameter search space in **Part 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "651d32596f089e5e6a6cc978c6f79cd6",
     "grade": true,
     "grade_id": "cell-6fecb92ed6ad5abe",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Our model was a pipeline of a vectorizer, to perform preprocessing on the text data, and an SVM classifier, to perform sentiment classification.\n",
    "\n",
    "The procedure was to perform a search on various hyperparameters of the model. This entailed choosing a set of hyperparameters to search for (in this case, $C$ and $\\gamma$ for the SVM), as well as various candidate values for these hyperparameters. Then, we fit a model using each possible combination of these hyperparameter values, and compared their performances (by accuracy) to choose the best combination. This was the grid search. Next, for a finer search, we defined a range of hyperparameter values close to the best values from the grid search, and performed a random search, in which we fit 5 models using a random combination of these new hyperparameter values.\n",
    "\n",
    "For the random search, I chose values which were between $a / 2$ and $3 a / 2$ for each best hyperparameter result $a$ from the grid search. The original grid search candidate values were orders of magnitude apart, which suggested that a search of values of the same order of magnitude might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
